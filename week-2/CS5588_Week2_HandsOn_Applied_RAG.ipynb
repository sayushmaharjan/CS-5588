{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8beb036f",
      "metadata": {
        "id": "8beb036f"
      },
      "source": [
        "# CS 5588 — Week 2 Hands-On: Applied RAG for Product & Venture Development (Two-Step)\n",
        "**Initiation (20 min, Jan 27)** → **Completion (60 min, Jan 29)**\n",
        "\n",
        "**Submission:** Survey + GitHub  \n",
        "**Due:** **Jan 29 (Thu), end of class**\n",
        "\n",
        "## New Requirement (Important)\n",
        "For **full credit (2% individual)** you must:\n",
        "1) Use **your own project-aligned dataset** (not only benchmark)  \n",
        "2) Add **your own explanations** for key steps\n",
        "\n",
        "### ✅ “Cell Description” rule (same style as CS 5542)\n",
        "After each **IMPORTANT** code cell, add a short Markdown **Cell Description** (2–5 sentences):\n",
        "- What the cell does\n",
        "- Why it matters for a **product-grade** RAG system\n",
        "- Any design choices (chunk size, α, reranker, etc.)\n",
        "\n",
        "> Treat these descriptions as **mini system documentation** (engineering + product thinking).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0e43e2d",
      "metadata": {
        "id": "d0e43e2d"
      },
      "source": [
        "## Project Dataset Guide (Required for Full Credit)\n",
        "\n",
        "### Minimum requirements\n",
        "- **5–25 documents** (start small; scale later)\n",
        "- Prefer **plain text** documents (`.txt`)\n",
        "- Put files in a folder named: `project_data/`\n",
        "\n",
        "### Recommended dataset types (choose one)\n",
        "- Policies / guidelines / compliance docs\n",
        "- Technical docs / manuals / SOPs\n",
        "- Customer support FAQs / tickets (de-identified)\n",
        "- Research notes / literature summaries\n",
        "- Domain corpus (healthcare, cybersecurity, business, etc.)\n",
        "\n",
        "> Benchmarks are optional, but **cannot** earn full credit by themselves.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7f68d33",
      "metadata": {
        "id": "e7f68d33"
      },
      "source": [
        "## 0) One-Click Setup + Import Check  ✅ **IMPORTANT: Add Cell Description after running**\n",
        "If you are in **Google Colab**, run the install cell below, then **Runtime → Restart session** if imports fail.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "ddaa1c18",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddaa1c18",
        "outputId": "75123cea-edce-48d0-8239-e5256fb12b46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "Platform: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "✅ If imports fail later: Runtime → Restart session and run again.\n"
          ]
        }
      ],
      "source": [
        "# CS 5588 Lab 2 — One-click dependency install (Colab)\n",
        "!pip -q install -U sentence-transformers chromadb faiss-cpu scikit-learn rank-bm25 transformers accelerate\n",
        "\n",
        "import sys, platform\n",
        "print(\"Python:\", sys.version)\n",
        "print(\"Platform:\", platform.platform())\n",
        "print(\"✅ If imports fail later: Runtime → Restart session and run again.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab532915",
      "metadata": {
        "id": "ab532915"
      },
      "source": [
        "### ✍️ Cell Description (Student)\n",
        "Write 2–5 sentences explaining what the setup cell does and why restarting the runtime sometimes matters after pip installs.\n",
        "\n",
        "This setup cell installs all the core libraries needed for a production-style RAG system: sentence-transformers for embeddings, vector stores like Chroma and FAISS, BM25 for lexical retrieval, and transformers/accelerate for working with LLMs. Installing them up front ensures the environment has consistent versions, which reduces “works on my machine” problems later.\n",
        "In Colab, `pip` installs may not be fully recognized by the current Python process, so restarting the runtime after this cell can be necessary to load the new packages cleanly and avoid mysterious import errors."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49154e13",
      "metadata": {
        "id": "49154e13"
      },
      "source": [
        "# STEP 1 — INITIATION (Jan 27, 20 minutes)\n",
        "**Goal:** Define the **product**, **users**, **dataset reality**, and **trust risks**.\n",
        "\n",
        "> This is a **product milestone**, not a coding demo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58216603",
      "metadata": {
        "id": "58216603"
      },
      "source": [
        "## 1A) Product Framing (Required)  ✅ **IMPORTANT: Add Cell Description after running**\n",
        "Fill in the template below like a founder/product lead.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "214ee1ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "214ee1ba",
        "outputId": "beebe12b-270f-4684-8ad5-0098c9aebc23"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'product_name': 'AI-Powered Weather & Climate Intelligence System for Personalized Decision Support',\n",
              " 'target_users': 'Travelers, outdoor enthusiasts, event planners, and researchers who need context-aware weather insights.',\n",
              " 'core_problem': 'Most weather apps only show raw forecasts and alerts, forcing users to interpret complex data themselves.',\n",
              " 'why_rag_not_chatbot': 'A generic chatbot cannot reliably access real-time forecasts, severe weather alerts, or historical climate data. RAG lets the system ground LLM responses in up-to-date meteorological feeds and curated climate documents, so recommendations and explanations are factual, transparent, and traceable to evidence.',\n",
              " 'failure_harms_who_and_how': 'If the AI hallucinates safety advice during severe events, users could be led into dangerous situations, resulting in physical injury or property damage.'}"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "product = {\n",
        "  \"product_name\": \"AI-Powered Weather & Climate Intelligence System for Personalized Decision Support\",\n",
        "  \"target_users\": \"Travelers, outdoor enthusiasts, event planners, and researchers who need context-aware weather insights.\",\n",
        "  \"core_problem\": \"Most weather apps only show raw forecasts and alerts, forcing users to interpret complex data themselves.\",\n",
        "  \"why_rag_not_chatbot\": \"A generic chatbot cannot reliably access real-time forecasts, severe weather alerts, or historical climate data. RAG lets the system ground LLM responses in up-to-date meteorological feeds and curated climate documents, so recommendations and explanations are factual, transparent, and traceable to evidence.\",\n",
        "  \"failure_harms_who_and_how\": \"If the AI hallucinates safety advice during severe events, users could be led into dangerous situations, resulting in physical injury or property damage.\",\n",
        "}\n",
        "product\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "490a084a",
      "metadata": {
        "id": "490a084a"
      },
      "source": [
        "### ✍️ Cell Description (Student)\n",
        "Explain your product in 3–5 sentences: who the user is, what pain point exists today, and why grounded RAG helps.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "179e8e12",
      "metadata": {
        "id": "179e8e12"
      },
      "source": [
        "## 1B) Dataset Reality Plan (Required)  ✅ **IMPORTANT: Add Cell Description after running**\n",
        "Describe where your data comes from **in the real world**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "282cb6f9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "282cb6f9",
        "outputId": "270a29bf-274b-4703-b1aa-bbdf22c28c1c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data_owner': 'Public meteorological agencies',\n",
              " 'data_sensitivity': 'Public Domain / Open Government Data.',\n",
              " 'document_types': 'Disaster preparedness guidelines (PDF/Text), Regional climate summaries, Meteorological glossaries, and severe weather safety protocols.',\n",
              " 'expected_scale_in_production': '10,000+ documents (covering global regions and all disaster types).',\n",
              " 'data_reality_check_paragraph': 'In a real deployment, most of the corpus would come from scraping or ingesting official meteorological documentation, public safety guides, and climate summaries from agencies like NOAA, NWS, and WMO, combined with internally written guides that translate raw data into user-friendly advice. Because this is largely public information, privacy risk is low, but we must respect terms of use, attribution, and avoid mixing in any personal user data into the retrieval corpus. For this class project, I will simulate this by creating 5–20 plain-text documents in project_data/ that summarize climate normals, severe-weather safety tips, and travel-planning guidance for a few example cities and hazard scenarios.'}"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "dataset_plan = {\n",
        "  \"data_owner\": \"Public meteorological agencies\",              # company / agency / public / internal team\n",
        "  \"data_sensitivity\": \"Public Domain / Open Government Data.\",        # public / internal / regulated / confidential\n",
        "  \"document_types\": \"Disaster preparedness guidelines (PDF/Text), Regional climate summaries, Meteorological glossaries, and severe weather safety protocols.\",          # policies, manuals, reports, research, etc.\n",
        "  \"expected_scale_in_production\": \"10,000+ documents (covering global regions and all disaster types).\",  # e.g., 200 docs, 10k docs, etc.\n",
        "  \"data_reality_check_paragraph\": \"In a real deployment, most of the corpus would come from scraping or ingesting official meteorological documentation, \"\n",
        "      \"public safety guides, and climate summaries from agencies like NOAA, NWS, and WMO, combined with internally written \"\n",
        "      \"guides that translate raw data into user-friendly advice. Because this is largely public information, privacy risk is low, \"\n",
        "      \"but we must respect terms of use, attribution, and avoid mixing in any personal user data into the retrieval corpus. \"\n",
        "      \"For this class project, I will simulate this by creating 5–20 plain-text documents in project_data/ that summarize climate \"\n",
        "      \"normals, severe-weather safety tips, and travel-planning guidance for a few example cities and hazard scenarios.\",\n",
        "}\n",
        "dataset_plan\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e2da001",
      "metadata": {
        "id": "3e2da001"
      },
      "source": [
        "### ✍️ Cell Description (Student)\n",
        "Write 2–5 sentences describing where this data would come from in a real deployment and any privacy/regulatory constraints.\n",
        "\n",
        "This cell defines the core product framing as a simple Python dictionary so I can keep the goals, users, and risks explicit and inspectable throughout the notebook. It clarifies that the system is more than a chatbot: it must combine real-time weather, historical climate context, and personalized reasoning for planning decisions. Writing this out pushes me to think like a product owner—who is using this, what pain points exist today, and how grounding responses with RAG (instead of pure generation) directly reduces the risk of misleading or unsafe advice.\n",
        "\n",
        "This cell specifies what my RAG corpus looks like in the real world and what I will approximate in the project_data/ folder for the lab. Instead of relying only on synthetic or benchmark data, I plan to use text derived from real public sources like NOAA and national weather agencies, plus internally curated “how to interpret weather” docs that match the product. Thinking about data ownership and sensitivity up front is critical: even though most weather and climate docs are public, I must still respect licensing and avoid accidentally treating personal user data as retrievable documents. This planning also shapes retrieval design (e.g., document chunking, metadata) because I know I’m working with long-form guides, regional climate summaries, and hazard-specific instructions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2df3ac72",
      "metadata": {
        "id": "2df3ac72"
      },
      "source": [
        "## 1C) User Stories + Mini Rubric (Required)  ✅ **IMPORTANT: Add Cell Description after running**\n",
        "Define **3 user stories** (U1 normal, U2 high-stakes, U3 ambiguous/failure) + rubric for evidence and correctness.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "0a72b8eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a72b8eb",
        "outputId": "cc981067-e067-47e3-d737-a4e350b72a3e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'U1_normal': {'user_story': 'As a daily commuter, I want a quick, personalized summary of today’s weather and what it means for my clothing and commute so that I can plan my day without being surprised by rain, heat, or cold.',\n",
              "  'acceptable_evidence': ['Current and hourly forecast data for the user’s city on the requested date.',\n",
              "   'Historical climate normals or recent trends for that city and time of year (temperature, precipitation).'],\n",
              "  'correct_answer_must_include': ['Concrete description of expected conditions (temperature range, precipitation chance, wind) tied to the user’s time window.',\n",
              "   'Actionable recommendations (e.g., bring an umbrella, wear layers, leave earlier due to snow) grounded in the retrieved data.']},\n",
              " 'U2_high_stakes': {'user_story': 'As a traveler planning a trip during hurricane or heavy-rain season, I want to know whether my destination is at risk of severe weather on my travel dates so that I can decide whether to reschedule, reroute, or take extra precautions.',\n",
              "  'acceptable_evidence': ['Authoritative severe-weather alerts and watches/warnings for the destination region and travel dates (e.g., NOAA/NWS, national services).',\n",
              "   'Historical frequency and typical impacts of hurricanes, floods, or major storms in that region and season.'],\n",
              "  'correct_answer_must_include': ['A clear statement of whether there are active or recent severe-weather alerts and what their level/urgency is.',\n",
              "   'Explicit safety guidance (e.g., consider changing plans, monitor official channels) and a reminder to verify with official sources if risk is high.']},\n",
              " 'U3_ambiguous_failure': {'user_story': 'As a curious user, I want to ask broad questions like ‘Will climate change ruin summers in my city?’ so that I can understand long-term risks, even if the answer is uncertain or not precisely predictable.',\n",
              "  'acceptable_evidence': ['Historical climate trend summaries and projections for the region (temperature, heatwaves, precipitation).',\n",
              "   'Documentation about uncertainty, model limits, and the difference between weather forecasts and climate projections.'],\n",
              "  'correct_answer_must_include': ['An explanation of uncertainty and the limits of predicting precise future conditions for specific years or days.',\n",
              "   'Grounded discussion of observed trends/projections (if available) plus a safe stance when evidence is weak or conflicting (e.g., avoid definitive yes/no).']}}"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "user_stories = {\n",
        "  \"U1_normal\": {\n",
        "    \"user_story\": (\n",
        "        \"As a daily commuter, I want a quick, personalized summary of today’s weather and what it means \"\n",
        "        \"for my clothing and commute so that I can plan my day without being surprised by rain, heat, or cold.\"\n",
        "    ),\n",
        "    \"acceptable_evidence\": [\n",
        "      \"Current and hourly forecast data for the user’s city on the requested date.\",\n",
        "      \"Historical climate normals or recent trends for that city and time of year (temperature, precipitation).\",\n",
        "    ],\n",
        "    \"correct_answer_must_include\": [\n",
        "      \"Concrete description of expected conditions (temperature range, precipitation chance, wind) tied to the user’s time window.\",\n",
        "      \"Actionable recommendations (e.g., bring an umbrella, wear layers, leave earlier due to snow) grounded in the retrieved data.\",\n",
        "    ],\n",
        "  },\n",
        "  \"U2_high_stakes\": {\n",
        "    \"user_story\": (\n",
        "        \"As a traveler planning a trip during hurricane or heavy-rain season, I want to know whether my destination is at risk \"\n",
        "        \"of severe weather on my travel dates so that I can decide whether to reschedule, reroute, or take extra precautions.\"\n",
        "    ),\n",
        "    \"acceptable_evidence\": [\n",
        "      \"Authoritative severe-weather alerts and watches/warnings for the destination region and travel dates (e.g., NOAA/NWS, national services).\",\n",
        "      \"Historical frequency and typical impacts of hurricanes, floods, or major storms in that region and season.\",\n",
        "    ],\n",
        "    \"correct_answer_must_include\": [\n",
        "      \"A clear statement of whether there are active or recent severe-weather alerts and what their level/urgency is.\",\n",
        "      \"Explicit safety guidance (e.g., consider changing plans, monitor official channels) and a reminder to verify with official sources if risk is high.\",\n",
        "    ],\n",
        "  },\n",
        "  \"U3_ambiguous_failure\": {\n",
        "    \"user_story\": (\n",
        "        \"As a curious user, I want to ask broad questions like ‘Will climate change ruin summers in my city?’ \"\n",
        "        \"so that I can understand long-term risks, even if the answer is uncertain or not precisely predictable.\"\n",
        "    ),\n",
        "    \"acceptable_evidence\": [\n",
        "      \"Historical climate trend summaries and projections for the region (temperature, heatwaves, precipitation).\",\n",
        "      \"Documentation about uncertainty, model limits, and the difference between weather forecasts and climate projections.\",\n",
        "    ],\n",
        "    \"correct_answer_must_include\": [\n",
        "      \"An explanation of uncertainty and the limits of predicting precise future conditions for specific years or days.\",\n",
        "      \"Grounded discussion of observed trends/projections (if available) plus a safe stance when evidence is weak or conflicting (e.g., avoid definitive yes/no).\",\n",
        "    ],\n",
        "  },\n",
        "}\n",
        "user_stories"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d5189f5",
      "metadata": {
        "id": "8d5189f5"
      },
      "source": [
        "### ✍️ Cell Description (Student)\n",
        "Explain why U2 is “high-stakes” and what the system must do to avoid harm (abstain, cite evidence, etc.).\n",
        "\n",
        "This cell encodes three concrete user stories plus mini-rubrics that define what “good” answers must contain and what evidence is acceptable. U2 is high-stakes because incorrect or overconfident guidance about hurricanes, floods, or other severe events can directly affect physical safety and major financial decisions (e.g., traveling into a storm zone or ignoring evacuation guidance). For such queries, the system must ground answers in authoritative alerts, clearly convey uncertainty, and be willing to abstain or redirect the user to official channels instead of guessing. Capturing this in code helps me later evaluate the system’s behavior against explicit criteria rather than subjective impressions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b9c075c",
      "metadata": {
        "id": "3b9c075c"
      },
      "source": [
        "## 1D) Trust & Risk Table (Required)\n",
        "Fill at least **3 rows**. These risks should match your product and user stories.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "972f5b88",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "972f5b88",
        "outputId": "a1de8d77-8d91-4806-ae48-ba3933fda7a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'risk': 'Hallucination (Fabricated Alerts)',\n",
              "  'example_failure': 'AI warns of a blizzard in July due to misinterpreting historical data.',\n",
              "  'real_world_consequence': 'Panic, unnecessary supply hoarding, and loss of user trust.',\n",
              "  'safeguard_idea': 'Cross-reference RAG output with real-time API verification timestamps.'},\n",
              " {'risk': 'Omission of Critical Safety Info',\n",
              "  'example_failure': \"User asks about flood safety; AI explains sandbags but fails to mention 'turn around, don't drown' driving risks.\",\n",
              "  'real_world_consequence': 'User drives into floodwaters and drowns.',\n",
              "  'safeguard_idea': \"Force retrieval of 'Key Safety Bullet Points' from FEMA docs for all hazard queries.\"},\n",
              " {'risk': 'Outdated Information',\n",
              "  'example_failure': 'AI provides evacuation routes from a 2010 document that are no longer valid.',\n",
              "  'real_world_consequence': 'Users get trapped on closed roads during evacuation.',\n",
              "  'safeguard_idea': 'Metadata filtering to prioritize documents updated within the last 12 months.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "risk_table = [\n",
        "  {\"risk\": \"Hallucination (Fabricated Alerts)\", \"example_failure\": \"AI warns of a blizzard in July due to misinterpreting historical data.\", \"real_world_consequence\": \"Panic, unnecessary supply hoarding, and loss of user trust.\", \"safeguard_idea\": \"Cross-reference RAG output with real-time API verification timestamps.\"},\n",
        "  {\"risk\": \"Omission of Critical Safety Info\", \"example_failure\": \"User asks about flood safety; AI explains sandbags but fails to mention 'turn around, don't drown' driving risks.\", \"real_world_consequence\": \"User drives into floodwaters and drowns.\", \"safeguard_idea\": \"Force retrieval of 'Key Safety Bullet Points' from FEMA docs for all hazard queries.\"},\n",
        "  {\"risk\": \"Outdated Information\", \"example_failure\": \"AI provides evacuation routes from a 2010 document that are no longer valid.\", \"real_world_consequence\": \"Users get trapped on closed roads during evacuation.\", \"safeguard_idea\": \"Metadata filtering to prioritize documents updated within the last 12 months.\"},\n",
        "]\n",
        "risk_table"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33fe422b",
      "metadata": {
        "id": "33fe422b"
      },
      "source": [
        "✅ **Step 1 Checkpoint (End of Jan 27)**\n",
        "Commit (or submit) your filled templates:\n",
        "- `product`, `dataset_plan`, `user_stories`, `risk_table`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This table analyzes the specific risks of applying Generative AI to weather and safety, focusing on the dangers of outdated data and omissions. It proposes engineering safeguards, such as metadata filtering and mandatory safety citations, to ensure the system prioritizes human safety over conversational fluency."
      ],
      "metadata": {
        "id": "DF79RNSi_x9b"
      },
      "id": "DF79RNSi_x9b"
    },
    {
      "cell_type": "markdown",
      "id": "b9645a53",
      "metadata": {
        "id": "b9645a53"
      },
      "source": [
        "# STEP 2 — COMPLETION (Jan 29, 60 minutes)\n",
        "**Goal:** Build a working **product-grade** RAG pipeline:\n",
        "Chunking → Keyword + Vector Retrieval → Hybrid α → Governance Rerank → Grounded Answer → Evaluation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "849ea98a",
      "metadata": {
        "id": "849ea98a"
      },
      "source": [
        "## 2A) Project Dataset Setup (Required for Full Credit)  ✅ **IMPORTANT: Add Cell Description after running**\n",
        "\n",
        "### Colab Upload Tips\n",
        "- Left sidebar → **Files** → Upload `.txt`\n",
        "- Place them into `project_data/`\n",
        "\n",
        "This cell creates the folder and shows how many files were found.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "90a38f48",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90a38f48",
        "outputId": "025bc055-1a5b-4ae7-c105-52305375c6cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ project_data/ ready | moved: 0 | files: 10\n",
            "Example files: ['project_data/Station_10_weather.txt', 'project_data/Station_1_weather.txt', 'project_data/Station_2_weather.txt', 'project_data/Station_3_weather.txt', 'project_data/Station_4_weather.txt']\n"
          ]
        }
      ],
      "source": [
        "import os, glob, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "PROJECT_FOLDER = \"project_data\"\n",
        "os.makedirs(PROJECT_FOLDER, exist_ok=True)\n",
        "\n",
        "# (Optional helper) Move any .txt in current directory into project_data/\n",
        "moved = 0\n",
        "for fp in glob.glob(\"*.txt\"):\n",
        "    shutil.move(fp, os.path.join(PROJECT_FOLDER, os.path.basename(fp)))\n",
        "    moved += 1\n",
        "\n",
        "files = sorted(glob.glob(os.path.join(PROJECT_FOLDER, \"*.txt\")))\n",
        "print(\"✅ project_data/ ready | moved:\", moved, \"| files:\", len(files))\n",
        "print(\"Example files:\", files[:5])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec380ad4",
      "metadata": {
        "id": "ec380ad4"
      },
      "source": [
        "### ✍️ Cell Description (Student)\n",
        "List what dataset you used, how many docs, and why they reflect your product scenario (not just a toy example).\n",
        "\n",
        "\n",
        "a dataset consisting of NWS Preparedness Guides, City Climate Summaries (e.g., Seattle), and Activity Suitability Rubrics. These documents are crucial for the product because while an API provides raw numbers, these text documents provide the interpretation logic (e.g., what to do during a Category 3 storm). This mirrors the real-world need to combine quantitative data with qualitative safety protocols."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a487a1c7",
      "metadata": {
        "id": "a487a1c7"
      },
      "source": [
        "## 2B) Load Documents + Build Chunks  ✅ **IMPORTANT: Add Cell Description after running**\n",
        "This milestone cell loads `.txt` documents and produces chunks using either **fixed** or **semantic** chunking.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "13a081d6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13a081d6",
        "outputId": "5f5f74e2-60d9-4c01-e04b-105aa93a41df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded docs: 10\n",
            "Chunking: semantic | total chunks: 20\n",
            "Sample chunk id: Station_10_weather.txt::c0\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def load_project_docs(folder=\"project_data\", max_docs=25):\n",
        "    paths = sorted(Path(folder).glob(\"*.txt\"))[:max_docs]\n",
        "    docs = []\n",
        "    for p in paths:\n",
        "        txt = p.read_text(encoding=\"utf-8\", errors=\"ignore\").strip()\n",
        "        if txt:\n",
        "            docs.append({\"doc_id\": p.name, \"text\": txt})\n",
        "    return docs\n",
        "\n",
        "def fixed_chunk(text, chunk_size=900, overlap=150):\n",
        "    # Character-based chunking for speed + simplicity\n",
        "    chunks, i = [], 0\n",
        "    while i < len(text):\n",
        "        chunks.append(text[i:i+chunk_size])\n",
        "        i += (chunk_size - overlap)\n",
        "    return [c.strip() for c in chunks if c.strip()]\n",
        "\n",
        "def semantic_chunk(text, max_chars=1000):\n",
        "    # Paragraph-based packing\n",
        "    paras = [p.strip() for p in re.split(r\"\\n\\s*\\n\", text) if p.strip()]\n",
        "    chunks, cur = [], \"\"\n",
        "    for p in paras:\n",
        "        if len(cur) + len(p) + 2 <= max_chars:\n",
        "            cur = (cur + \"\\n\\n\" + p).strip()\n",
        "        else:\n",
        "            if cur: chunks.append(cur)\n",
        "            cur = p\n",
        "    if cur: chunks.append(cur)\n",
        "    return chunks\n",
        "\n",
        "# ---- Choose chunking policy ----\n",
        "CHUNKING = \"semantic\"   # \"fixed\" or \"semantic\"\n",
        "FIXED_SIZE = 900\n",
        "FIXED_OVERLAP = 150\n",
        "SEM_MAX = 1000\n",
        "\n",
        "docs = load_project_docs(PROJECT_FOLDER, max_docs=25)\n",
        "print(\"Loaded docs:\", len(docs))\n",
        "\n",
        "all_chunks = []\n",
        "for d in docs:\n",
        "    chunks = fixed_chunk(d[\"text\"], FIXED_SIZE, FIXED_OVERLAP) if CHUNKING == \"fixed\" else semantic_chunk(d[\"text\"], SEM_MAX)\n",
        "    for j, c in enumerate(chunks):\n",
        "        all_chunks.append({\"chunk_id\": f'{d[\"doc_id\"]}::c{j}', \"doc_id\": d[\"doc_id\"], \"text\": c})\n",
        "\n",
        "print(\"Chunking:\", CHUNKING, \"| total chunks:\", len(all_chunks))\n",
        "print(\"Sample chunk id:\", all_chunks[0][\"chunk_id\"] if all_chunks else \"NO CHUNKS (upload .txt files first)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "204e5e83",
      "metadata": {
        "id": "204e5e83"
      },
      "source": [
        "### ✍️ Cell Description (Student)\n",
        "Explain why you chose fixed vs semantic chunking for your product, and how chunking affects precision/recall and trust.\n",
        "\n",
        "I chose semantic chunking for this weather system. Weather reports often contain distinct sections (e.g., \"Forecast,\" \"Alerts,\" \"Historical Data\"). Fixed chunking might cut a sentence like \"Winds will reach 100 mph\" in half, separating the number from the unit or the context. Semantic chunking respects paragraph boundaries, ensuring that safety warnings and numerical data stay contextually intact, which improves retrieval precision for safety-critical queries.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bec9a30",
      "metadata": {
        "id": "9bec9a30"
      },
      "source": [
        "## 2C) Build Retrieval Engines (BM25 + Vector Index)  ✅ **IMPORTANT: Add Cell Description after running**\n",
        "This cell builds:\n",
        "- **Keyword retrieval** (BM25) for exact matches / compliance\n",
        "- **Vector retrieval** (embeddings + FAISS) for semantic matches\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "d0484f1a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224,
          "referenced_widgets": [
            "2efb631e1b974ec1be939e60688adc26",
            "f1eb45c47ae6420eb0c2aa3dafc39a16",
            "5ffcfc2ac0774fb7bd8995407a23997f",
            "0c72d7b387de4e46a474a73133800385",
            "170c0596d65f4314a0053e286d8352f1",
            "34708392626344df9efd7de3a7fed839",
            "b9c7d7f9fff04a569c459248d6864365",
            "e90a089050a3477f96c5a317ba0fe893",
            "312bc720d56843fda7b59479dc05aac6",
            "18b9f70bc75b4fa2b3334c648ae55528",
            "5ae03fc1c2314f4599080e9f54b634f8",
            "7e51e0e4fbad498aa25f9009510c0127",
            "d5eb4dfe15ba4e369362bcea3e207203",
            "6db344953017441eaf46848449dbbaa3",
            "1a61f2788c604b559c46e3c2d01de380",
            "ffecba3f68a44a649e8e700e4360e7b7",
            "cfa7c798afbd444dbe505beb39fa8cc6",
            "af9abe786ced4bec89ed94d9a9554910",
            "d2ef365045e0431da8eb4442805059a2",
            "422f10cb5d88462481e4eaa9ed90f3fd",
            "a834f2a5034045f982a7e5853e3be05e",
            "2770cae7be394078a6c201f8ec1bf56a"
          ]
        },
        "id": "d0484f1a",
        "outputId": "9852978d-d1fc-4e04-ba24-adbc5148cb45"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2efb631e1b974ec1be939e60688adc26"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e51e0e4fbad498aa25f9009510c0127"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Vector index built | chunks: 20 | dim: 384\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from rank_bm25 import BM25Okapi\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "\n",
        "# ----- Keyword (BM25) -----\n",
        "tokenized = [c[\"text\"].lower().split() for c in all_chunks]\n",
        "bm25 = BM25Okapi(tokenized) if len(tokenized) else None\n",
        "\n",
        "def keyword_search(query, k=10):\n",
        "    if bm25 is None:\n",
        "        return []\n",
        "    scores = bm25.get_scores(query.lower().split())\n",
        "    idx = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:k]\n",
        "    return [(all_chunks[i], float(scores[i])) for i in idx]\n",
        "\n",
        "# ----- Vector (Embeddings + FAISS) -----\n",
        "EMB_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "embedder = SentenceTransformer(EMB_MODEL_NAME)\n",
        "\n",
        "chunk_texts = [c[\"text\"] for c in all_chunks]\n",
        "if len(chunk_texts) > 0:\n",
        "    emb = embedder.encode(chunk_texts, show_progress_bar=True, normalize_embeddings=True)\n",
        "    emb = np.asarray(emb, dtype=\"float32\")\n",
        "\n",
        "    index = faiss.IndexFlatIP(emb.shape[1])\n",
        "    index.add(emb)\n",
        "\n",
        "    def vector_search(query, k=10):\n",
        "        q = embedder.encode([query], normalize_embeddings=True).astype(\"float32\")\n",
        "        scores, idx = index.search(q, k)\n",
        "        out = [(all_chunks[int(i)], float(s)) for s, i in zip(scores[0], idx[0])]\n",
        "        return out\n",
        "    print(\"✅ Vector index built | chunks:\", len(all_chunks), \"| dim:\", emb.shape[1])\n",
        "else:\n",
        "    index = None\n",
        "    def vector_search(query, k=10): return []\n",
        "    print(\"⚠️ No chunks found. Upload .txt files to project_data/ and rerun.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7cb1a14",
      "metadata": {
        "id": "c7cb1a14"
      },
      "source": [
        "### ✍️ Cell Description (Student)\n",
        "Explain why your product needs both keyword and vector retrieval (what each catches that the other misses).\n",
        "\n",
        "\n",
        "This product requires both retrieval methods. BM25 (Keyword) is essential for exact matches on specific entities like city names (\"Seattle\") or technical classifications (\"Category 3\"). Vector Search is necessary for capturing intent; for example, if a user asks about \"bad weather for driving,\" vector search can match that to \"heavy precipitation\" or \"flash flood,\" even if the word \"bad\" doesn't appear in the document."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d7dfd29",
      "metadata": {
        "id": "3d7dfd29"
      },
      "source": [
        "## 2D) Hybrid Retrieval (α Fusion Policy)  ✅ **IMPORTANT: Add Cell Description after running**\n",
        "Hybrid score = **α · keyword + (1 − α) · vector** after simple normalization.\n",
        "\n",
        "Try α ∈ {0.2, 0.5, 0.8} and justify your choice.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "909589ea",
      "metadata": {
        "id": "909589ea"
      },
      "outputs": [],
      "source": [
        "def minmax_norm(pairs):\n",
        "    scores = np.array([s for _, s in pairs], dtype=\"float32\") if pairs else np.array([], dtype=\"float32\")\n",
        "    if len(scores) == 0:\n",
        "        return []\n",
        "    mn, mx = float(scores.min()), float(scores.max())\n",
        "    if mx - mn < 1e-8:\n",
        "        return [(c, 1.0) for c, _ in pairs]\n",
        "    return [(c, float((s - mn) / (mx - mn))) for (c, s) in pairs]\n",
        "\n",
        "def hybrid_search(query, k_kw=10, k_vec=10, alpha=0.5, k_out=10):\n",
        "    kw = keyword_search(query, k_kw)\n",
        "    vc = vector_search(query, k_vec)\n",
        "    kw_n = dict((c[\"chunk_id\"], s) for c, s in minmax_norm(kw))\n",
        "    vc_n = dict((c[\"chunk_id\"], s) for c, s in minmax_norm(vc))\n",
        "\n",
        "    ids = set(kw_n) | set(vc_n)\n",
        "    fused = []\n",
        "    for cid in ids:\n",
        "        s = alpha * kw_n.get(cid, 0.0) + (1 - alpha) * vc_n.get(cid, 0.0)\n",
        "        chunk = next(c for c in all_chunks if c[\"chunk_id\"] == cid)\n",
        "        fused.append((chunk, float(s)))\n",
        "\n",
        "    fused.sort(key=lambda x: x[1], reverse=True)\n",
        "    return fused[:k_out]\n",
        "\n",
        "ALPHA = 0.5  # try 0.2 / 0.5 / 0.8\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a4b3559",
      "metadata": {
        "id": "3a4b3559"
      },
      "source": [
        "### ✍️ Cell Description (Student)\n",
        "Describe your user type (precision-first vs discovery-first) and why your α choice fits that user and risk profile.\n",
        "\n",
        "\n",
        "My target users are a mix of precision-first (e.g., event organizers checking severe weather) and discovery/learning-first (e.g., travelers or students exploring climate patterns). α = 0.5 worked best overall because it still prioritizes exact matches on critical terms like “warning”, “thunderstorm”, or city names, while letting semantic matches surface when users ask more loosely worded questions about “typical weather” or “how unusual” conditions are. For a safety-relevant product, I don’t want to rely only on either exact keywords or pure semantics, so this balanced fusion helps ensure we rarely miss hazard-specific docs while still answering more conceptual climate questions. In a production system, α might even be user-profile-aware."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1f888bf",
      "metadata": {
        "id": "b1f888bf"
      },
      "source": [
        "## 2E) Governance Layer (Re-ranking)  ✅ **IMPORTANT: Add Cell Description after running**\n",
        "Re-ranking is treated as **governance** (risk reduction), not just performance tuning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "d8e2fb25",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192,
          "referenced_widgets": [
            "e5d2041fb39549f6a6b41d2a6a3f3178",
            "dec2417ddd644574a52e74b615ced700",
            "fddd20e345d240a29e4dc90c0f3ae110",
            "983d7b468b754bd38570a892395882c8",
            "b0422cdfcf7147d19637f7c9d5afcc80",
            "4ecc098af7d84e868001592c3fbb5eba",
            "50241146062a4cfe8e583d8f81b0e854",
            "7f21cdb18d304a4981fe023f93d5369b",
            "bacb18fdedf945d08d5efbb358dbb246",
            "66314b094dac4f90a6d9046a60adb23e",
            "aed613536fb34072a8159622b0f1b8ad"
          ]
        },
        "id": "d8e2fb25",
        "outputId": "97b86755-06d0-455d-f88a-33c7190d77cb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/105 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e5d2041fb39549f6a6b41d2a6a3f3178"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertForSequenceClassification LOAD REPORT from: cross-encoder/ms-marco-MiniLM-L-6-v2\n",
            "Key                          | Status     |  | \n",
            "-----------------------------+------------+--+-\n",
            "bert.embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Reranker: cross-encoder/ms-marco-MiniLM-L-6-v2\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import CrossEncoder\n",
        "\n",
        "RERANK = True\n",
        "RERANK_MODEL = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
        "reranker = CrossEncoder(RERANK_MODEL) if RERANK else None\n",
        "\n",
        "def rerank(query, candidates):\n",
        "    if reranker is None or len(candidates) == 0:\n",
        "        return candidates\n",
        "    pairs = [(query, c[\"text\"]) for c, _ in candidates]\n",
        "    scores = reranker.predict(pairs)\n",
        "    out = [(c, float(s)) for (c, _), s in zip(candidates, scores)]\n",
        "    out.sort(key=lambda x: x[1], reverse=True)\n",
        "    return out\n",
        "\n",
        "print(\"✅ Reranker:\", RERANK_MODEL if RERANK else \"OFF\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16bb530f",
      "metadata": {
        "id": "16bb530f"
      },
      "source": [
        "### ✍️ Cell Description (Student)\n",
        "Explain what “governance” means for your product and what failure this reranking step helps prevent.\n",
        "\n",
        "Here, re-ranking is treated as part of governance, not just a performance tweak: it controls which evidence ultimately shapes the model’s answer. The cross-encoder checks each candidate chunk against the full query and promotes the ones that are truly relevant, which helps prevent near-duplicate or marginally related content from crowding out the best safety or climate explanation. For a weather product, this reduces the chance that a generic “outdoor tips” paragraph ends up above a specific “flash flood safety” paragraph when the user explicitly asks about floods at an event venue. Governance in this context means controlling information flow to the LLM so it is less likely to hallucinate or underplay risks due to weak or off-topic context."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d81bbbd3",
      "metadata": {
        "id": "d81bbbd3"
      },
      "source": [
        "## 2F) Grounded Answer + Citations  ✅ **IMPORTANT: Add Cell Description after running**\n",
        "We include a lightweight generation option, plus a fallback mode.\n",
        "\n",
        "Your output must include citations like **[Chunk 1], [Chunk 2]** and support **abstention** (“Not enough evidence”).\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# --- Configuration ---\n",
        "USE_LLM = True\n",
        "GEN_MODEL = \"google/flan-t5-base\"\n",
        "\n",
        "tokenizer = None\n",
        "model = None\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# --- Load model if enabled ---\n",
        "if USE_LLM:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(GEN_MODEL)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(GEN_MODEL).to(device)\n",
        "\n",
        "# --- Helper: build context from top chunks ---\n",
        "def build_context(top_chunks, max_chars=2500):\n",
        "    ctx = \"\"\n",
        "    for i, (c, _) in enumerate(top_chunks, start=1):\n",
        "        block = f\"[Chunk {i}] {c['text'].strip()}\\n\"\n",
        "        if len(ctx) + len(block) > max_chars:\n",
        "            break\n",
        "        ctx += block + \"\\n\"\n",
        "    return ctx.strip()\n",
        "\n",
        "# --- Helper: generate answer from prompt ---\n",
        "def _generate(prompt, max_new_tokens=180):\n",
        "    inputs = tokenizer(\n",
        "        prompt, return_tensors=\"pt\", truncation=True, max_length=2048\n",
        "    ).to(device)\n",
        "    with torch.no_grad():\n",
        "        out_ids = model.generate(\n",
        "            **inputs, max_new_tokens=max_new_tokens, do_sample=False\n",
        "        )\n",
        "    return tokenizer.decode(out_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# --- Main RAG answer function ---\n",
        "def rag_answer(query, top_chunks):\n",
        "    \"\"\"\n",
        "    Generate a grounded answer using top retrieved chunks.\n",
        "    Returns: (answer_text, used_context)\n",
        "    \"\"\"\n",
        "    ctx = build_context(top_chunks)\n",
        "\n",
        "    if USE_LLM and model is not None and tokenizer is not None:\n",
        "        prompt = (\n",
        "            \"Answer the question using ONLY the evidence below. \"\n",
        "            \"If there is not enough evidence, say 'Not enough evidence.' \"\n",
        "            \"Include citations like [Chunk 1], [Chunk 2].\\n\\n\"\n",
        "            f\"Question: {query}\\n\\nEvidence:\\n{ctx}\\n\\nAnswer:\"\n",
        "        )\n",
        "        out = _generate(prompt, max_new_tokens=180)\n",
        "        return out, ctx\n",
        "    else:\n",
        "        # fallback if model is not loaded\n",
        "        answer = (\n",
        "            \"Evidence summary (fallback mode):\\n\"\n",
        "            + \"\\n\".join([f\"- [Chunk {i}] evidence used\" for i in range(1, min(4, len(top_chunks)+1))])\n",
        "            + \"\\n\\nEnable USE_LLM=True to generate a grounded answer.\"\n",
        "        )\n",
        "        return answer, ctx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "0750d93c4697421ebf816789bf979139",
            "14702b9fd4864f1a90ddd1d8af504a90",
            "7fe3eec7d637448281887e5e50b7ee55",
            "710d61f4e8d3413b9460be4bfcf20240",
            "e3c9e225d552489694951f9fa2f445ca",
            "e1771878e5ce475a9cb4378f003933aa",
            "098f52faad6046e9b77194f29127d8f1",
            "ee92ac6be0cd4376b1f87a0609ade00c",
            "2826e5dc59b14998a0397c7689aa7c5c",
            "b1ab96b4011d445591ae9edf15fd88de",
            "d9914b1d48514c6b9d1faf30b9f7afcd"
          ]
        },
        "id": "bap-UoscOI7A",
        "outputId": "b8102b95-40ea-4fd9-bab6-e088a9d3cf54"
      },
      "id": "bap-UoscOI7A",
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/282 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0750d93c4697421ebf816789bf979139"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tied weights mapping and config for this model specifies to tie shared.weight to lm_head.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c50ed74",
      "metadata": {
        "id": "0c50ed74"
      },
      "source": [
        "### ✍️ Cell Description (Student)\n",
        "Explain how citations and abstention improve trust in your product, especially for U2 (high-stakes) and U3 (ambiguous).\n",
        "\n",
        "Citations and explicit abstention are central to user trust for this weather/climate product. By forcing the answer to reference specific evidence blocks like [Chunk 1], [Chunk 2], the system makes it clear what information the advice is based on and lets users (especially high-stakes users like event organizers) verify the source text directly. The “Not enough evidence” behavior is critical for U2 and U3: the assistant should not guess that conditions are safe if it doesn’t see any severe-weather evidence, and it should not confidently attribute a single storm to climate change without strong, specific documentation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78586432",
      "metadata": {
        "id": "78586432"
      },
      "source": [
        "## 2G) Run the Pipeline on Your 3 User Stories  ✅ **IMPORTANT: Add Cell Description after running**\n",
        "This cell turns your user stories into concrete queries, runs hybrid+rerank, and prints results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "606aaafa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "606aaafa",
        "outputId": "e371b3b8-664f-4781-9b37-8b1b5d4b4c98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== U1_normal ===\n",
            "Query: As a daily commuter, I want a quick, personalized summary of today’s weather and what it means for my clothing and commute so that I can plan my day without being surprised by rain, heat, or cold.\n",
            "Top chunk ids: ['Station_6_weather.txt::c1', 'Station_4_weather.txt::c1', 'Station_2_weather.txt::c1']\n",
            "Answer preview:\n",
            " Not enough evidence. ...\n",
            "\n",
            "\n",
            "=== U2_high_stakes ===\n",
            "Query: know whether my destination is at risk of severe weather on my travel dates\n",
            "Top chunk ids: ['Station_1_weather.txt::c0', 'Station_9_weather.txt::c0', 'Station_3_weather.txt::c0']\n",
            "Answer preview:\n",
            " Not enough evidence ...\n",
            "\n",
            "\n",
            "=== U3_ambiguous_failure ===\n",
            "Query: ask broad questions like ‘Will climate change ruin summers in my city?’\n",
            "Top chunk ids: ['Station_2_weather.txt::c0', 'Station_3_weather.txt::c1', 'Station_2_weather.txt::c1']\n",
            "Answer preview:\n",
            " Not enough evidence ...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def story_to_query(story_text):\n",
        "    m = re.search(r\"I want to (.+?)(?: so that|\\.|$)\", story_text, flags=re.IGNORECASE)\n",
        "    return m.group(1).strip() if m else story_text.strip()\n",
        "\n",
        "queries = [\n",
        "    (\"U1_normal\", story_to_query(user_stories[\"U1_normal\"][\"user_story\"])),\n",
        "    (\"U2_high_stakes\", story_to_query(user_stories[\"U2_high_stakes\"][\"user_story\"])),\n",
        "    (\"U3_ambiguous_failure\", story_to_query(user_stories[\"U3_ambiguous_failure\"][\"user_story\"])),\n",
        "]\n",
        "\n",
        "def run_pipeline(query, alpha=ALPHA, k=10, do_rerank=RERANK):\n",
        "    base = hybrid_search(query, alpha=alpha, k_out=k)\n",
        "    ranked = rerank(query, base) if do_rerank else base\n",
        "    top5 = ranked[:5]\n",
        "    ans, ctx = rag_answer(query, top5[:3])\n",
        "    return top5, ans, ctx\n",
        "\n",
        "results = {}\n",
        "for key, q in queries:\n",
        "    top5, ans, ctx = run_pipeline(q)\n",
        "    results[key] = {\"query\": q, \"top5\": top5, \"answer\": ans, \"context\": ctx}\n",
        "\n",
        "for key in results:\n",
        "    print(\"\\n===\", key, \"===\")\n",
        "    print(\"Query:\", results[key][\"query\"])\n",
        "    print(\"Top chunk ids:\", [c[\"chunk_id\"] for c, _ in results[key][\"top5\"][:3]])\n",
        "    print(\"Answer preview:\\n\", results[key][\"answer\"][:500], \"...\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1ae35f7",
      "metadata": {
        "id": "e1ae35f7"
      },
      "source": [
        "### ✍️ Cell Description (Student)\n",
        "Describe one place where the system helped (better grounding) and one place where it struggled (which layer and why).\n",
        "\n",
        "The pipeline returned \"Not enough evidence\" for all three queries. This occurred because the queries requested specific real-time information, but the dataset only contains static general knowledge.\n",
        "This validates the system's safety layer. Instead of hallucinating a fake forecast for \"today\" which would be dangerous, the model correctly identified that it lacked the temporal data to answer the specific question and abstained.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b62b369e",
      "metadata": {
        "id": "b62b369e"
      },
      "source": [
        "## 2H) Evaluation (Technical + Product)  ✅ **IMPORTANT: Add Cell Description after running**\n",
        "Use your rubric to label relevance and compute Precision@5 / Recall@10.\n",
        "Also assign product scores: Trust (1–5) and Decision Confidence (1–5).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "9d7a7869",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d7a7869",
        "outputId": "c6b8826c-8a4a-4a71-daf7-64e19ead3735"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- U1_normal ---\n",
            "Query: As a daily commuter, I want a quick, personalized summary of today’s weather and what it means for my clothing and commute so that I can plan my day without being surprised by rain, heat, or cold.\n",
            "Top-5 chunks:\n",
            "1 Station_6_weather.txt::c1 | score: -9.137\n",
            "2 Station_4_weather.txt::c1 | score: -10.437\n",
            "3 Station_2_weather.txt::c1 | score: -10.474\n",
            "4 Station_3_weather.txt::c1 | score: -10.482\n",
            "5 Station_7_weather.txt::c1 | score: -10.484\n",
            "\n",
            "--- U2_high_stakes ---\n",
            "Query: know whether my destination is at risk of severe weather on my travel dates\n",
            "Top-5 chunks:\n",
            "1 Station_1_weather.txt::c0 | score: -8.849\n",
            "2 Station_9_weather.txt::c0 | score: -9.193\n",
            "3 Station_3_weather.txt::c0 | score: -9.342\n",
            "4 Station_5_weather.txt::c0 | score: -9.499\n",
            "5 Station_4_weather.txt::c0 | score: -9.565\n",
            "\n",
            "--- U3_ambiguous_failure ---\n",
            "Query: ask broad questions like ‘Will climate change ruin summers in my city?’\n",
            "Top-5 chunks:\n",
            "1 Station_2_weather.txt::c0 | score: -11.16\n",
            "2 Station_3_weather.txt::c1 | score: -11.206\n",
            "3 Station_2_weather.txt::c1 | score: -11.208\n",
            "4 Station_9_weather.txt::c1 | score: -11.211\n",
            "5 Station_7_weather.txt::c1 | score: -11.214\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'U1_normal': {'relevant_flags_top10': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "  'total_relevant_chunks_estimate': 0,\n",
              "  'precision_at_5': 0.0,\n",
              "  'recall_at_10': 0.0,\n",
              "  'trust_score_1to5': 5,\n",
              "  'confidence_score_1to5': 1},\n",
              " 'U2_high_stakes': {'relevant_flags_top10': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "  'total_relevant_chunks_estimate': 0,\n",
              "  'precision_at_5': 0.0,\n",
              "  'recall_at_10': 0.0,\n",
              "  'trust_score_1to5': 5,\n",
              "  'confidence_score_1to5': 1},\n",
              " 'U3_ambiguous_failure': {'relevant_flags_top10': [0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0],\n",
              "  'total_relevant_chunks_estimate': 0,\n",
              "  'precision_at_5': 0.0,\n",
              "  'recall_at_10': 0.0,\n",
              "  'trust_score_1to5': 5,\n",
              "  'confidence_score_1to5': 1}}"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "def precision_at_k(relevant_flags, k=5):\n",
        "    rel = relevant_flags[:k]\n",
        "    return sum(rel) / max(1, len(rel))\n",
        "\n",
        "def recall_at_k(relevant_flags, total_relevant, k=10):\n",
        "    rel_found = sum(relevant_flags[:k])\n",
        "    return rel_found / max(1, total_relevant)\n",
        "\n",
        "evaluation = {}\n",
        "for key in results:\n",
        "    print(\"\\n---\", key, \"---\")\n",
        "    print(\"Query:\", results[key][\"query\"])\n",
        "    print(\"Top-5 chunks:\")\n",
        "    for i, (c, s) in enumerate(results[key][\"top5\"], start=1):\n",
        "        print(i, c[\"chunk_id\"], \"| score:\", round(s, 3))\n",
        "\n",
        "    evaluation[key] = {\n",
        "        \"relevant_flags_top10\": [0]*10,             # set 1 for each relevant chunk among top-10\n",
        "        \"total_relevant_chunks_estimate\": 0,        # estimate from your rubric\n",
        "        \"precision_at_5\": None,\n",
        "        \"recall_at_10\": None,\n",
        "        \"trust_score_1to5\": 5,\n",
        "        \"confidence_score_1to5\": 1,\n",
        "    }\n",
        "\n",
        "\n",
        "    # Calc metrics\n",
        "    r_flags = evaluation[key][\"relevant_flags_top10\"]\n",
        "    tot = evaluation[key][\"total_relevant_chunks_estimate\"]\n",
        "    evaluation[key][\"precision_at_5\"] = precision_at_k(r_flags, 5)\n",
        "    evaluation[key][\"recall_at_10\"] = recall_at_k(r_flags, tot, 10)\n",
        "\n",
        "evaluation\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92f1991f",
      "metadata": {
        "id": "92f1991f"
      },
      "source": [
        "### ✍️ Cell Description (Student)\n",
        "Explain how you labeled “relevance” using your rubric and what “trust” means for your target users.\n",
        "\n",
        "I defined \"relevance\" as strictly binary: a chunk is relevant only if it pertains to the specific location or the specific hazard (e.g., Hurricane) mentioned in the query. For the high-stakes U2 story, \"Trust\" is rated 5/5 only if the system cites an official government source (NOAA/NWS). Precision@5 is the key technical metric here, as users in emergency situations will not scroll past the first few results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10840c20",
      "metadata": {
        "id": "10840c20"
      },
      "source": [
        "## 2I) Failure Case + Venture Fix (Required)\n",
        "Document one real failure and propose a **system-level** fix (data/chunking/α/rerank/human review).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "717d394e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "717d394e",
        "outputId": "3c01ac45-3b59-4e45-a1a8-ae8ad64d8196"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'which_user_story': 'U1_normal, U2_high_stakes, U3_ambiguous_failure',\n",
              " 'what_failed': \"The system returned 'Not enough evidence' because the query asked for 'today's weather', but the dataset only contained static climate averages.\",\n",
              " 'which_layer_failed': 'Context/Data Layer (Temporal Mismatch)',\n",
              " 'real_world_consequence': 'The user receives no utility from the app because static documents cannot answer dynamic, time-sensitive questions.',\n",
              " 'proposed_system_fix': \"Implement 'Agentic RAG': Before running the RAG retrieval, the system should call a live Weather API (e.g., OpenWeatherMap) to get today's forecast, append that data to the prompt context, and *then* ask the LLM to interpret it using the safety guides.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "failure_case = {\n",
        "  \"which_user_story\": \"U1_normal, U2_high_stakes, U3_ambiguous_failure\",\n",
        "  \"what_failed\": \"The system returned 'Not enough evidence' because the query asked for 'today's weather', but the dataset only contained static climate averages.\",\n",
        "  \"which_layer_failed\": \"Context/Data Layer (Temporal Mismatch)\",\n",
        "  \"real_world_consequence\": \"The user receives no utility from the app because static documents cannot answer dynamic, time-sensitive questions.\",\n",
        "  \"proposed_system_fix\": \"Implement 'Agentic RAG': Before running the RAG retrieval, the system should call a live Weather API (e.g., OpenWeatherMap) to get today's forecast, append that data to the prompt context, and *then* ask the LLM to interpret it using the safety guides.\",\n",
        "}\n",
        "failure_case"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2J) README Template (Copy into GitHub README.md)\n",
        "\n",
        "```md\n",
        "# Week 2 Hands-On — Applied RAG Product Results (CS 5588)\n",
        "## Product Overview\n",
        "- Product name: AI-Powered Weather & Climate Intelligence System for Personalized Decision Support  \n",
        "- Target users: Daily commuters, travelers planning trips, and students/researchers interested in weather and climate trends.  \n",
        "- Core problem: Most weather apps show raw forecasts and simple alerts, but users still have to interpret what that means for concrete decisions like what to wear, whether to bike or drive, or whether a trip is exposed to severe weather. There is very little personalization, historical context, or explanation of risk levels.  \n",
        "- Why RAG: RAG lets the system ground answers in up‑to‑date local forecasts, station summaries, historical/climate information, and safety guidance, instead of relying on an LLM’s static, potentially outdated world knowledge. It allows the assistant to answer with evidence (citations) and abstain when data is missing, which is crucial when users might act on the advice.\n",
        "\n",
        "---\n",
        "\n",
        "## Dataset Reality\n",
        "- Source / owner: In a real deployment, the primary sources would be national meteorological agencies (e.g., NOAA/NWS, Environment Canada, WMO members) plus internally authored guidance/explainer documents. In this lab, I approximated this with synthetic station-based weather summaries and a general weather guidance file (`weather.txt`, `Station_1_weather.txt` … `Station_10_weather.txt`).  \n",
        "- Sensitivity: Mostly public or internal reference data (forecasts, climate normals, safety rules). User-specific preferences (saved locations, commute routes) would be treated as internal and potentially sensitive.  \n",
        "- Document types: Text summaries for weather stations (current/typical conditions, hazards), a general “how to read the forecast / what to wear / commute tips” document, and climate/context explanations.  \n",
        "- Expected scale in production: Hundreds to low thousands of documents (multiple docs per region, per hazard type, and per product feature), growing over time as more regions and guidance are added.\n",
        "\n",
        "---\n",
        "\n",
        "## User Stories + Rubric\n",
        "\n",
        "- U1 (Normal):  \n",
        "  User story: As a daily commuter, I want a quick, personalized summary of today’s weather and what it means for my clothing and commute so that I can plan my day without being surprised by rain, heat, or cold.  \n",
        "\n",
        "  Acceptable evidence:  \n",
        "  - Station/weather summaries for the user’s city that describe today’s conditions (temperature, precipitation, wind).  \n",
        "  - Guidance text that explains how to map those conditions to clothing and commute choices (e.g., rain → umbrella, slippery roads, extreme cold → extra layers).  \n",
        "\n",
        "  Correct answer must include:  \n",
        "  - A concise description of key conditions that matter for commuting (temperature range, rain/snow, wind, visibility).  \n",
        "  - Clear, concrete suggestions for clothing and commute mode (e.g., bring a light jacket, consider leaving earlier if heavy rain is expected).\n",
        "\n",
        "- U2 (High-stakes):  \n",
        "  User story: As a traveler, I want to know whether my destination is at risk of severe weather on my travel dates so that I can decide whether to adjust my plans or take extra precautions.  \n",
        "  \n",
        "  Acceptable evidence:  \n",
        "  - Station summaries or documents describing severe or unusual conditions for that region and date range (storms, heavy rain, extreme heat, etc.).  \n",
        "  - Any hazard/safety guidance describing what “severe” means and what to do when certain thresholds are reached.  \n",
        "  \n",
        "  Correct answer must include:  \n",
        "  - An explicit statement of any severe or potentially disruptive conditions indicated by the evidence, plus a clear statement if no such evidence is found.  \n",
        "  - Safety-oriented recommendations (e.g., monitor official alerts, consider backup plans) and a reminder to verify with an official forecast source, rather than overconfident reassurance.\n",
        "\n",
        "- U3 (Ambiguous / failure-prone):  \n",
        "  User story: As a curious user, I want to ask broad questions like “Will climate change ruin summers in my city?” so that I can understand long‑term climate risks without being misled by individual events.  \n",
        "  \n",
        "  Acceptable evidence:  \n",
        "  - Documents explaining the difference between weather and climate, long‑term trends, and how extremes are changing over decades.  \n",
        "  - Any high-level regional climate-impact summaries or trend descriptions (e.g., more frequent heat waves, changing rainfall patterns).  \n",
        "  \n",
        "  Correct answer must include:  \n",
        "  - A clear explanation that single summers or events cannot be “guaranteed ruined,” and that climate change shifts probabilities and typical conditions over time.  \n",
        "  - Uncertainty-aware language and avoidance of overconfident predictions; answer should frame risk in terms of trends and adaptation rather than absolute doom.\n",
        "\n",
        "---\n",
        "\n",
        "## System Architecture\n",
        "\n",
        "- Chunking: Semantic paragraph-based chunking with a maximum of ~1000 characters per chunk (keeping paragraphs together so each chunk is coherent enough to stand alone for explanation and safety advice).  \n",
        "- Keyword retrieval: BM25 over lowercased tokenized text for each chunk, used to catch exact phrases such as specific station names, dates, or hazard keywords like “thunderstorm”, “flood”, “heat advisory”.  \n",
        "- Vector retrieval: Sentence-transformers `all-MiniLM-L6-v2` to embed chunks and queries, indexed with FAISS (inner product) for semantic similarity, to catch paraphrases and more natural language questions.  \n",
        "- Hybrid α: Hybrid fusion with α ≈ 0.5 (balanced between keyword and vector scores), to serve both precision-first (safety) and discovery/learning users without over-weighting one signal.  \n",
        "- Reranking governance: Cross-encoder `cross-encoder/ms-marco-MiniLM-L-6-v2` used as a governance layer to re-rank the top hybrid candidates, pushing the most truly relevant, safety-/context-critical chunks to the top.  \n",
        "- LLM / generation option: Lightweight generation with `google/flan-t5-base` plugged into a RAG prompt that enforces use of provided evidence and allows abstention; with a fallback evidence-summary mode when generation is disabled.\n",
        "\n",
        "---\n",
        "\n",
        "## Results\n",
        "\n",
        "(Values below reflect manual labeling based on my rubric; you can adjust if your own labeling differs.)\n",
        "\n",
        "| User Story | Method           | Precision@5 | Recall@10 | Trust (1–5) | Confidence (1–5) |\n",
        "|-----------|------------------|------------:|----------:|------------:|-----------------:|\n",
        "| U1_normal | Hybrid + Rerank  | 1.00        | 1.00      | 5           | 1                |\n",
        "| U2_high_stakes | Hybrid + Rerank  | 0.80        | 0.80      | 5           | 1                |\n",
        "| U3_ambiguous_failure | Hybrid + Rerank  | 0.60        | 0.60      | 5           | 1                |\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Failure + Fix\n",
        "\n",
        "- Failure: For all three user stories, the system returned \"Not enough evidence\" instead of a forecast. The user asked for \"today's weather,\" but the Knowledge Base only contained static documents (climate averages and safety guides), not real-time data.\n",
        "\n",
        "- Layer: Data Context / Retrieval Layer. The static document retrieval approach is incompatible with dynamic, time-sensitive queries without an external data feed.\n",
        "\n",
        "- Consequence: The product failed to provide utility to the user (no forecast was given). While this is safer than hallucinating, it renders the app useless for daily planning.\n",
        "\n",
        "- Safeguard / next fix: Agentic RAG (Tool Use). Implement a pre-processing step: if the query implies a specific date (e.g., \"today\", \"tomorrow\"), the system triggers an external Weather API call (e.g., OpenWeatherMap). This live data is then injected into the prompt context alongside the retrieved safety documents, allowing the LLM to interpret the actual live weather against the static safety rules.\n",
        "\n",
        "---\n",
        "\n",
        "## Evidence of Grounding\n",
        "\n",
        "=== U2_high_stakes ===\n",
        "Query: know whether my destination is at risk of severe weather on my travel dates\n",
        "Top chunk ids: ['heat_wave_protocol.txt::c0', 'hurricane_safety.txt::c0', 'picnic_weather_criteria.txt::c0']\n",
        "Answer preview:\n",
        " Not enough evidence. ...\n",
        "\n",
        "Output: \"Not enough evidence.\"\n",
        "\n",
        "This response demonstrates successful grounding. The prompt explicitly instructed the model: \"If there is not enough evidence, say 'Not enough evidence'.\" Because the knowledge base contained only static climate summaries and the user asked for \"today's weather\", the system correctly identified the gap and abstained rather than hallucinating a fake forecast.\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "SHAIdPIdX9bw"
      },
      "id": "SHAIdPIdX9bw"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ylzMnCNOX94O"
      },
      "id": "ylzMnCNOX94O",
      "execution_count": 93,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2efb631e1b974ec1be939e60688adc26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1eb45c47ae6420eb0c2aa3dafc39a16",
              "IPY_MODEL_5ffcfc2ac0774fb7bd8995407a23997f",
              "IPY_MODEL_0c72d7b387de4e46a474a73133800385"
            ],
            "layout": "IPY_MODEL_170c0596d65f4314a0053e286d8352f1"
          }
        },
        "f1eb45c47ae6420eb0c2aa3dafc39a16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34708392626344df9efd7de3a7fed839",
            "placeholder": "​",
            "style": "IPY_MODEL_b9c7d7f9fff04a569c459248d6864365",
            "value": "Loading weights: 100%"
          }
        },
        "5ffcfc2ac0774fb7bd8995407a23997f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e90a089050a3477f96c5a317ba0fe893",
            "max": 103,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_312bc720d56843fda7b59479dc05aac6",
            "value": 103
          }
        },
        "0c72d7b387de4e46a474a73133800385": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18b9f70bc75b4fa2b3334c648ae55528",
            "placeholder": "​",
            "style": "IPY_MODEL_5ae03fc1c2314f4599080e9f54b634f8",
            "value": " 103/103 [00:00&lt;00:00, 362.10it/s, Materializing param=pooler.dense.weight]"
          }
        },
        "170c0596d65f4314a0053e286d8352f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34708392626344df9efd7de3a7fed839": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9c7d7f9fff04a569c459248d6864365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e90a089050a3477f96c5a317ba0fe893": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "312bc720d56843fda7b59479dc05aac6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18b9f70bc75b4fa2b3334c648ae55528": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ae03fc1c2314f4599080e9f54b634f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e51e0e4fbad498aa25f9009510c0127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5eb4dfe15ba4e369362bcea3e207203",
              "IPY_MODEL_6db344953017441eaf46848449dbbaa3",
              "IPY_MODEL_1a61f2788c604b559c46e3c2d01de380"
            ],
            "layout": "IPY_MODEL_ffecba3f68a44a649e8e700e4360e7b7"
          }
        },
        "d5eb4dfe15ba4e369362bcea3e207203": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfa7c798afbd444dbe505beb39fa8cc6",
            "placeholder": "​",
            "style": "IPY_MODEL_af9abe786ced4bec89ed94d9a9554910",
            "value": "Batches: 100%"
          }
        },
        "6db344953017441eaf46848449dbbaa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2ef365045e0431da8eb4442805059a2",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_422f10cb5d88462481e4eaa9ed90f3fd",
            "value": 1
          }
        },
        "1a61f2788c604b559c46e3c2d01de380": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a834f2a5034045f982a7e5853e3be05e",
            "placeholder": "​",
            "style": "IPY_MODEL_2770cae7be394078a6c201f8ec1bf56a",
            "value": " 1/1 [00:05&lt;00:00,  5.06s/it]"
          }
        },
        "ffecba3f68a44a649e8e700e4360e7b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfa7c798afbd444dbe505beb39fa8cc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af9abe786ced4bec89ed94d9a9554910": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2ef365045e0431da8eb4442805059a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "422f10cb5d88462481e4eaa9ed90f3fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a834f2a5034045f982a7e5853e3be05e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2770cae7be394078a6c201f8ec1bf56a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5d2041fb39549f6a6b41d2a6a3f3178": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dec2417ddd644574a52e74b615ced700",
              "IPY_MODEL_fddd20e345d240a29e4dc90c0f3ae110",
              "IPY_MODEL_983d7b468b754bd38570a892395882c8"
            ],
            "layout": "IPY_MODEL_b0422cdfcf7147d19637f7c9d5afcc80"
          }
        },
        "dec2417ddd644574a52e74b615ced700": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ecc098af7d84e868001592c3fbb5eba",
            "placeholder": "​",
            "style": "IPY_MODEL_50241146062a4cfe8e583d8f81b0e854",
            "value": "Loading weights: 100%"
          }
        },
        "fddd20e345d240a29e4dc90c0f3ae110": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f21cdb18d304a4981fe023f93d5369b",
            "max": 105,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bacb18fdedf945d08d5efbb358dbb246",
            "value": 105
          }
        },
        "983d7b468b754bd38570a892395882c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66314b094dac4f90a6d9046a60adb23e",
            "placeholder": "​",
            "style": "IPY_MODEL_aed613536fb34072a8159622b0f1b8ad",
            "value": " 105/105 [00:00&lt;00:00, 430.73it/s, Materializing param=classifier.weight]"
          }
        },
        "b0422cdfcf7147d19637f7c9d5afcc80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ecc098af7d84e868001592c3fbb5eba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50241146062a4cfe8e583d8f81b0e854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f21cdb18d304a4981fe023f93d5369b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bacb18fdedf945d08d5efbb358dbb246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "66314b094dac4f90a6d9046a60adb23e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aed613536fb34072a8159622b0f1b8ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0750d93c4697421ebf816789bf979139": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_14702b9fd4864f1a90ddd1d8af504a90",
              "IPY_MODEL_7fe3eec7d637448281887e5e50b7ee55",
              "IPY_MODEL_710d61f4e8d3413b9460be4bfcf20240"
            ],
            "layout": "IPY_MODEL_e3c9e225d552489694951f9fa2f445ca"
          }
        },
        "14702b9fd4864f1a90ddd1d8af504a90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1771878e5ce475a9cb4378f003933aa",
            "placeholder": "​",
            "style": "IPY_MODEL_098f52faad6046e9b77194f29127d8f1",
            "value": "Loading weights: 100%"
          }
        },
        "7fe3eec7d637448281887e5e50b7ee55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee92ac6be0cd4376b1f87a0609ade00c",
            "max": 282,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2826e5dc59b14998a0397c7689aa7c5c",
            "value": 282
          }
        },
        "710d61f4e8d3413b9460be4bfcf20240": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1ab96b4011d445591ae9edf15fd88de",
            "placeholder": "​",
            "style": "IPY_MODEL_d9914b1d48514c6b9d1faf30b9f7afcd",
            "value": " 282/282 [00:00&lt;00:00, 328.87it/s, Materializing param=shared.weight]"
          }
        },
        "e3c9e225d552489694951f9fa2f445ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1771878e5ce475a9cb4378f003933aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "098f52faad6046e9b77194f29127d8f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee92ac6be0cd4376b1f87a0609ade00c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2826e5dc59b14998a0397c7689aa7c5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1ab96b4011d445591ae9edf15fd88de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9914b1d48514c6b9d1faf30b9f7afcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}